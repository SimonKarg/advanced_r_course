---
title: "Prepare data for qualtrics - human annotation"
author: "Simon Karg"
date: '2022-06-17'
output: html_document
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

# Documentation

This script takes the reference tweets and reply tweets from the
American Panel and prepares them to be entered in a qualtrics survey.

We're using the qualtrics Loop and Merge functionality to do this. Since
qualtrics does not allow .csv import for loop and merge, we need to be
creative. This is the workflow adopted:

1.  Download the blueprint qualtrics survey (in .qsf format, which is
    basically a .json format)
2.  Look for the "Static" loop object in the .qsf and replace the
    content with the texts in the same format
3.  Save the the file, and import it back into qualtrics

In order to do this, we need to create a file that has the reference
tweet and reply tweet in the expected structure, which looks like this:

> {
>
> "1": {
>
> "1": "reference tweet 1",
>
> "2": "reply to reference tweet 1"
>
> },
>
> "2": {
>
> "1": "reference tweet 2",
>
> "2": "reply to reference tweet 2"
>
> },
>
> ...
>
> }

To do this, we adopt an ad-hoc approach which isn't ideal, but gets the job done.

After this, we split the data into six datasets:

1. First 200 tweet pairs, labelled by all 5 annotators
2. The rest, 3639 tweet pairs, which labelled by 3 out of 5 annotators, such that all annotator combinations (3 out of 5) are equally likely. Since qualtrics does not offer an easy way to split data among annotators in the loop and merge functionality, we prepare a dataset for each annotator, i.e. 5 in total.


# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
options(scipen=999)
library(tidyverse)
```

Load data: we load the dataset with the texts to be labelled, and the qualtrics .qsf for reference

```{r}
# data to label (in columns ref_status.text, and full_text)
complete_dat <- read_csv("data/hand_coding_data/full_dataset_to_code/hate_incivil_anon_complete.csv")
```

```{r}
# load the .qsf
# qualt <- jsonlite::fromJSON(file.choose())
```

## Examine data structure of the .qsf
```{r}
# str(qualt$SurveyElements$Payload[[1]]$Options$LoopingOptions$Static)
# 
# old_static <- qualt$SurveyElements$Payload[[1]]$Options$LoopingOptions$Static
# 
# names(old_static)
# 
# old_static[[1]]
```


The "static" element of the .qsf is basically a data.frame with in which the items are nested data.frames

In order to mimick this data structure, we create a nested list, as this is easier to create, and actually closer to creating the desired output than creating a nested data.frame, when saving it with jsonlite::write_json()

*NOTE* this does not create the exact structure that we can copy paste into the .qsf file. Some post-processing needs to be done: We need to remove all square brackets ("[", "]") from the file. We do this with a simple search and replace in a subsequent step.



# First 200 tweet-pairs

## Preprocess
```{r}
empty_list <- list()
n_tweet_pairs <- 200

first_200 <- complete_dat %>% 
  select(id, ref_status.text, full_text) %>%
  head(200)


# Rearrange for second attempt (i.e. updated coding scheme, v.3)
first_200_rearranged <- rbind(first_200[c(100:115),],
                              first_200[c(1:99),],
                              first_200[c(116:200),])



for(i in (1:n_tweet_pairs)){
  tmp_list <- list(`1` = first_200_rearranged["ref_status.text"][[1]][i],
                 `2` = first_200_rearranged["full_text"][[1]][i])
  
  names(tmp_list) <- c("1","2")
  
  empty_list[[i]] <- tmp_list
}

names(empty_list) <- c(1:n_tweet_pairs)

empty_list

empty_list %>% jsonlite::write_json("first_200_tweetpairs_to_process.json")

```

## Post processing

Read in the .json file and remove the square brackets..
```{r}
to_process <- read_file("first_200_tweetpairs_to_process.json")

# remove [] brackets. 
# To leave brackets that are within tweets we're looking for brackets after a :
# or after which there is a , 
processed <- to_process %>% 
  str_replace_all(":\\[", ":") %>% 
  str_replace_all("\\]\\}", "\\}") %>% 
  str_replace_all("\\],", ",") 

# processed
write_file(processed, "first_200_tweetpairs_processed.json")

# save a reference to keep track of tweet ids
first_200_rearranged %>% 
  add_rownames() %>% 
  write.csv("hand coding/data/qualtrics_approach/first_200_ra_tweetpairs_ids.csv", row.names = FALSE)
```


# Rest dataset

This creates the 5 datasets and .qsf files for the 5 different coders.

## Preprocess

Define annotator scheme, such that all annotators combinations are equally likely. 
```{r}
coder_set <- data.frame(
  coder1 = c(1,1,1,1,1,1,0,0,0,0),
  coder2 = c(1,1,1,0,0,0,1,1,1,0),
  coder3 = c(1,0,0,1,1,0,1,1,0,1),
  coder4 = c(0,1,0,1,0,1,1,0,1,1),
  coder5 = c(0,0,1,0,1,1,0,1,1,1)
) %>% 
  mutate(comb_id = row_number())
```

add annotator scheme to dataset
```{r}
rest_dat <- complete_dat[201:nrow(complete_dat),] %>% 
  mutate(comb_id = c(rep(1:10, times = 563), c(1:9))) %>% 
  left_join(coder_set, by = c("comb_id" = "comb_id"))
```

create dataset for each annotator
```{r}
coder1_df <- rest_dat %>% filter(coder1 == 1)
coder2_df <- rest_dat %>% filter(coder2 == 1)
coder3_df <- rest_dat %>% filter(coder3 == 1)
coder4_df <- rest_dat %>% filter(coder4 == 1)
coder5_df <- rest_dat %>% filter(coder5 == 1)
```



```{r}
preprocess <- function(dataset){
  empty_list <- list()
  
  for(i in (1:nrow(dataset))){
    tmp_list <- list(`1` = dataset["ref_status.text"][[1]][i],
                   `2` = dataset["full_text"][[1]][i])
    
    names(tmp_list) <- c("1","2")
    
    empty_list[[i]] <- tmp_list
  }
  
  names(empty_list) <- c(1:nrow(dataset))
  
  return(empty_list)
}

coder1_preprocessed <- preprocess(coder1_df)
coder2_preprocessed <- preprocess(coder2_df)
coder3_preprocessed <- preprocess(coder3_df)
coder4_preprocessed <- preprocess(coder4_df)
coder5_preprocessed <- preprocess(coder5_df)

# save
coder1_preprocessed %>% jsonlite::write_json("data/qualtrics_approach/coder1_pre.json")
coder2_preprocessed %>% jsonlite::write_json("data/qualtrics_approach/coder2_pre.json")
coder3_preprocessed %>% jsonlite::write_json("data/qualtrics_approach/coder3_pre.json")
coder4_preprocessed %>% jsonlite::write_json("data/qualtrics_approach/coder4_pre.json")
coder5_preprocessed %>% jsonlite::write_json("data/qualtrics_approach/coder5_pre.json")
```

## Post processing

Read in the .json file and remove the square brackets..
```{r}
post_process <- function(path){
  dataset <- read_file(path)
  
  path_out <- str_replace(path, "pre", "post")
  
  dataset %>%  
    str_replace_all(":\\[", ":") %>% 
    str_replace_all("\\]\\}", "\\}") %>% 
    str_replace_all("\\],", ",") %>% 
    write_file(path_out)
  
}

post_process("data/qualtrics_approach/coder1_pre.json")
post_process("data/qualtrics_approach/coder2_pre.json")
post_process("data/qualtrics_approach/coder3_pre.json")
post_process("data/qualtrics_approach/coder4_pre.json")
post_process("data/qualtrics_approach/coder5_pre.json")

# save ids
coder1_df %>% 
  select(id, 
         ref_status.text, 
         full_text, 
         starts_with("coder")) %>% 
  write.csv("data/qualtrics_approach/coder1_ids.csv", row.names = FALSE)

coder2_df %>% 
  select(id, 
         ref_status.text, 
         full_text, 
         starts_with("coder")) %>% 
  write.csv("data/qualtrics_approach/coder2_ids.csv", row.names = FALSE)

coder3_df %>% 
  select(id, 
         ref_status.text, 
         full_text, 
         starts_with("coder")) %>% 
  write.csv("data/qualtrics_approach/coder3_ids.csv", row.names = FALSE)

coder4_df %>% 
  select(id, 
         ref_status.text, 
         full_text, 
         starts_with("coder")) %>% 
  write.csv("data/qualtrics_approach/coder4_ids.csv", row.names = FALSE)

coder5_df %>% 
  select(id, 
         ref_status.text, 
         full_text, 
         starts_with("coder")) %>% 
  write.csv("data/qualtrics_approach/coder5_ids.csv", row.names = FALSE)
```



# New approach: divide coder datasets into chunks of 500

This strategy became necessary after realizing that qualtrics breaks after a certain number of loops ~ 950
--> breaking up tweet pairs into chunks of 500 (except for Mette / coder 3, who only did 135 so far, so her chunks are larger)
--> creating .qsf files for these chunks

The approach is to prepare the tweet pairs as json files, broken up into the different chunks. Because coders got to different numbers of tweets before qualtrics broke, we have different breakpoints for the chunks. Especially mette has larger chunks (around 750 tweet pairs), which still should be save.


## Coder 1 (Laura)

### prepare json data
```{r}
coder1_json_post_complete <- jsonlite::read_json("hand coding/qualtrics_templates/coder1_post.json")

save_json_data <- function(json_complete_data, coder, breakpoints){
  jsonlite::write_json(json_complete_data[c(breakpoints[1]:breakpoints[2])], 
                       glue::glue("hand coding/qualtrics_templates/chunks/coder{coder}/coder{coder}_chunk1.json"))
  
  jsonlite::write_json(json_complete_data[c((breakpoints[2] + 1):breakpoints[3])], 
                       glue::glue("hand coding/qualtrics_templates/chunks/coder{coder}/coder{coder}_chunk2.json"))
  
  jsonlite::write_json(json_complete_data[c((breakpoints[3] + 1):breakpoints[4])], 
                       glue::glue("hand coding/qualtrics_templates/chunks/coder{coder}/coder{coder}_chunk3.json"))
  
  jsonlite::write_json(json_complete_data[c((breakpoints[4] + 1):breakpoints[5])], 
                       glue::glue("hand coding/qualtrics_templates/chunks/coder{coder}/coder{coder}_chunk4.json"))
  
  jsonlite::write_json(json_complete_data[c((breakpoints[5] + 1):breakpoints[6])], 
                       glue::glue("hand coding/qualtrics_templates/chunks/coder{coder}/coder{coder}_chunk5.json"))
  
  jsonlite::write_json(json_complete_data[c((breakpoints[6] + 1):length(json_complete_data))], 
                       glue::glue("hand coding/qualtrics_templates/chunks/coder{coder}/coder{coder}_chunk6.json"))
}

save_json_data(coder1_json_post_complete, "1", breakpoints = c(1,
                                                               953,
                                                               1500,
                                                               2000,
                                                               2500,
                                                               3000))
```


### save id data

These are the files that allow us to join the coded data coming from qualtrics with the twitter status ids. 
*ONLY THE TWITTER STATUS IDS ARE UNIQUE!* - everything else will have duplicates, since it's basically just rownames for the different files.

```{r}
save_ids <- function(coder_dataset, coder, breakpoints){
  # select relevant data to save
  coder_df_ids <- coder_dataset %>% 
    rownames_to_column() %>% 
    select(tweet_order_id = rowname,
           twitter_status_id = id, 
           ref_status.text, 
           full_text, 
           starts_with("coder"))
  
  # save in chunks according to breakpoints
  coder_df_ids[c(breakpoints[1]:breakpoints[2]),] %>% 
    write.csv(glue::glue("hand coding/qualtrics_templates/chunks/coder{coder}/coder{coder}_ids_chunk1.csv"),
              row.names = FALSE)
  
  coder_df_ids[c((breakpoints[2] + 1):breakpoints[3]),] %>% 
    write.csv(glue::glue("hand coding/qualtrics_templates/chunks/coder{coder}/coder{coder}_ids_chunk2.csv"),
              row.names = FALSE)
  
  coder_df_ids[c((breakpoints[3] + 1):breakpoints[4]),] %>% 
    write.csv(glue::glue("hand coding/qualtrics_templates/chunks/coder{coder}/coder{coder}_ids_chunk3.csv"),
              row.names = FALSE)
  
  coder_df_ids[c((breakpoints[4] + 1):breakpoints[5]),] %>% 
    write.csv(glue::glue("hand coding/qualtrics_templates/chunks/coder{coder}/coder{coder}_ids_chunk4.csv"),
              row.names = FALSE)
  
  coder_df_ids[c((breakpoints[5] + 1):breakpoints[6]),] %>% 
    write.csv(glue::glue("hand coding/qualtrics_templates/chunks/coder{coder}/coder{coder}_ids_chunk5.csv"),
              row.names = FALSE)
  
  coder_df_ids[c((breakpoints[6] + 1):nrow(coder_df_ids)),] %>% 
    write.csv(glue::glue("hand coding/qualtrics_templates/chunks/coder{coder}/coder{coder}_ids_chunk6.csv"),
              row.names = FALSE)
}
```


```{r}
save_ids(coder1_df, "1", breakpoints = c(1, 
                                         953, 
                                         1500,
                                         2000,
                                         2500,
                                         3000))
```



## Coder 2 (Christian)

### prepare json data
```{r}
coder2_json_post_complete <- jsonlite::read_json("hand coding/qualtrics_templates/coder2_post.json")
```

```{r}
save_json_data(coder2_json_post_complete, 
               "2", 
               breakpoints = c(1,
                               958,
                               1500,
                               2000,
                               2500,
                               3000))
```


### save ids
```{r}
save_ids(coder2_df, "2", breakpoints = c(1, 
                                         958, 
                                         1500,
                                         2000,
                                         2500,
                                         3000))
```

## Coder 3 (Mette)

### json
```{r}
coder3_json_complete <- jsonlite::read_json("hand coding/qualtrics_templates/coder3_post.json")
```

```{r}
save_json_data(coder3_json_complete, 
               "3", 
               breakpoints = c(1,
                               300,
                               750,
                               1500,
                               2250,
                               3000))
```


###  ids
```{r}
save_ids(coder3_df, "3", breakpoints = c(1,
                               300,
                               750,
                               1500,
                               2250,
                               3000))
```

## Coder 4 (Jesper)

### json
```{r}
coder4_json_complete <- jsonlite::read_json("hand coding/qualtrics_templates/coder4_post.json")

save_json_data(coder4_json_complete, 
               "4", 
               breakpoints = c(1,
                               954,
                               1500,
                               2000,
                               2500,
                               3000))
```

### ids
```{r}
save_ids(coder4_df, "4", breakpoints = c(1, 
                                         954, 
                                         1500,
                                         2000,
                                         2500,
                                         3000))
```

## Coder 5 (Ninna)

### json
```{r}
coder5_json_complete <- jsonlite::read_json("hand coding/qualtrics_templates/coder5_post.json")

save_json_data(coder5_json_complete, 
               "5", 
               breakpoints = c(1,
                               955,
                               1500,
                               2000,
                               2500,
                               3000))

```

### ids
```{r}
save_ids(coder5_df, "5", breakpoints = c(1, 
                                         955, 
                                         1500,
                                         2000,
                                         2500,
                                         3000))
```


# change blueprints and save them
```{r}
blueprint <- read_file("hand coding/qualtrics_templates/qualtrics_survey_templates/blueprint.qsf")
coder_names <- list("Laura", "Christian","Mette","Jesper", "Ninna")

create_qsf_files <- function(coder){
  
  # each coder has 6 chunks, so creating all of them in a loop
  for(chunk_number in seq_along(1:6)){
    
    print(chunk_number)
    
    # read in tweet pairs for specific chunk
    chunk_json_file <- read_file(
      glue::glue("hand coding/qualtrics_templates/chunks/coder{coder}/coder{coder}_chunk{chunk_number}.json")) %>% 
      
      # remove square brackets so qualtrics doesn't get confused
      str_remove_all(pattern = "\\[") %>% 
      str_remove_all(pattern = "\\]")
      
    
    # put in tweet pairs in qsf blueprint 
    chunk_qsf_file <- blueprint %>% 
      
      # update qualtrics survey name
      str_replace(fixed("labelling_counterspeech_first_200 - new_design"), 
                  glue::glue("coder{coder}_{coder_names[as.numeric(coder)]}_coding_guide_v3_chunk{chunk_number}")) %>%
      
      # fill in tweet pairs, these should be placed in the curly brackets after "Static" 
      str_replace(pattern = fixed("\"Static\": {}"), 
                  paste("\"Static\":", 
                        chunk_json_file))
    
    # write
    write_file(chunk_qsf_file, 
               glue::glue("hand coding/qualtrics_templates/chunks/coder{coder}/c{coder}_{coder_names[as.numeric(coder)]}_qsf_chunk{chunk_number}.qsf"))
  }
  
}
```


```{r}
create_qsf_files(coder = "1")
create_qsf_files(coder = "2")
create_qsf_files(coder = "3")
create_qsf_files(coder = "4")
create_qsf_files(coder = "5")
```


